{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of words: 66523\n",
      "[['the', 3361], ['to', 1652], ['of', 1363], ['i', 970], ['that', 899], ['we', 776], ['you', 585], ['for', 510], ['on', 490], ['up', 453], ['is', 387], ['not', 380], ['said', 358], ['would', 352], ['have', 330], ['be', 317], ['out', 274], ['so', 272], ['when', 264], ['them', 239]]\n",
      "---------------------\n",
      "['aback', 'abandon', 'abbeythe', 'ability', 'abingdonwas', 'abounds', 'aboutsome', 'abreast', 'abruptly', 'absorbing', 'abstain', 'abstract', 'absurdity', 'absurdly', 'abuse', 'accepted', 'accepting', 'accidentally', 'accidentpleasures', 'accommodating']\n",
      "---------------------\n",
      "There are 7305 unique words in this book.\n",
      "---------------------\n",
      "[['said', 355], ['harris', 264], ['one', 218], ['boat', 179], ['got', 152], ['man', 140], ['round', 133], ['go', 120], ['old', 119], ['two', 115], ['little', 114], ['never', 109], ['went', 97], ['seemed', 97], ['way', 95], ['came', 94], ['thing', 89], ['take', 85], ['well', 84], ['first', 76]]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from heapq import heappop, heappush\n",
    "from nltk.corpus import stopwords\n",
    "import re, string\n",
    "\n",
    "\n",
    "def format_word(s):\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in s if ch not in exclude)\n",
    "\n",
    "def remove_number(str):\n",
    "    if re.sub(r'\\d+', '', str) == str:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get20MostFrequentWords(dic):\n",
    "    heap = []\n",
    "    mostFrequent = []\n",
    "    #stop_words = set(stopwords.words(\"english\"))\n",
    "    #if key not in stop_words:\n",
    "    for key, value in dic.items():\n",
    "        heapq.heappush(heap,(-value,key))\n",
    "    for i in range(20):\n",
    "        mostFrequent.append([heapq.heappop(heap)[1],-heapq.heappop(heap)[0]])\n",
    "    return mostFrequent\n",
    "    \n",
    "def get20LeastFrequentWords(dic):\n",
    "    heap = []\n",
    "    leastFrequent = []\n",
    "    for key, value in dic.items():\n",
    "        heapq.heappush(heap,(value,key))\n",
    "    for i in range(20):\n",
    "        leastFrequent.append(heapq.heappop(heap)[1])\n",
    "    return leastFrequent \n",
    "\n",
    "      \n",
    "def getTotalUniqueWords(dic):\n",
    "    return \"There are \"+ str(len(dic)) + \" unique words in this book.\"\n",
    "\n",
    "\n",
    "def get20MostInterestingFrequentWords(dic):\n",
    "    heap = []\n",
    "    mostFrequent = []\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    #if key not in stop_words:\n",
    "    for key, value in dic.items():\n",
    "        if key not in stop_words:\n",
    "            heapq.heappush(heap,(-value,key))\n",
    "    for i in range(20):\n",
    "        mostFrequent.append([heapq.heappop(heap)[1],-heapq.heappop(heap)[0]])\n",
    "    return mostFrequent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Analyze the progression of the words used on a chapter-by-chapter basis\n",
    "\n",
    "'''\n",
    "    Figure out how to break down a book by chapter\n",
    "    #Make an array of dictionary - each dictionary is a chapter. \n",
    "\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    #Reading in text file \n",
    "    file = open(\"308.txt\",\"r\")\n",
    "    \n",
    "    '''\n",
    "        Functions to implement \n",
    "        \n",
    "        1. getTotalNumberOfWords()\n",
    "        2. getTotalUniqueWords()\n",
    "        3. get20MostFrequentWords()\n",
    "        4. get20MostInterestingFrequentWords()\n",
    "        5. get20LeastFrequentWords()\n",
    "        6. getFrequencyOfWord()\n",
    "        7. getChapterQuoteAppears()\n",
    "        8. generateSentence()\n",
    "    '''\n",
    "    #Dictionary =\n",
    "    characters = {\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\n",
    "                  \"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\n",
    "                  \"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\n",
    "                  \"u\",\"v\",\"w\",\"x\",\"y\",\"z\"}\n",
    "    wordCount = 0   \n",
    "    dic = defaultdict(int)\n",
    "    for line in file:\n",
    "        #Use Regular expressions to just get the words\n",
    "        for word in line.split():\n",
    "            word = format_word(word)\n",
    "            if remove_number(word):\n",
    "                dic[word.lower()] += 1\n",
    "                wordCount += 1\n",
    "    print(\"Total Number of words:\",wordCount)    \n",
    "    #Using Heaps - For top 20, least frequent \n",
    "    print(get20MostFrequentWords(dic))\n",
    "    print(\"---------------------\")\n",
    "    print(get20LeastFrequentWords(dic))\n",
    "    print(\"---------------------\")\n",
    "    print(getTotalUniqueWords(dic))\n",
    "    print(\"---------------------\")\n",
    "    print(get20MostInterestingFrequentWords(dic))\n",
    "\n",
    "      \n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
